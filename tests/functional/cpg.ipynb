{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19630fa",
   "metadata": {},
   "source": [
    "# CPG: Central Pattern Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import nevergrad as ng\n",
    "import numpy as np\n",
    "import torch\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "from rich.traceback import install\n",
    "\n",
    "# Local libraries\n",
    "from ariel.simulation.controllers import NaCPG\n",
    "from ariel.simulation.controllers.na_cpg import create_fully_connected_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA SETUP --- #\n",
    "CWD = Path.cwd()\n",
    "DATA = CWD / \"__data__\"\n",
    "DATA.mkdir(exist_ok=True)\n",
    "\n",
    "# --- RANDOM GENERATOR SETUP --- #\n",
    "SEED = 42\n",
    "RNG = np.random.default_rng(SEED)\n",
    "\n",
    "# --- TERMINAL OUTPUT SETUP --- #\n",
    "install(show_locals=False)\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67398a0",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_beta(\n",
    "    a: float,\n",
    "    b: float,\n",
    "    size: int | list[int],\n",
    "    c: float = 0,\n",
    "    d: float = 1,\n",
    "    *,\n",
    "    negative_reflect: bool = True,\n",
    "):\n",
    "    # a & b must be grater than 0\n",
    "    lower = min(c, d)\n",
    "    upper = max(c, d)\n",
    "\n",
    "    # If negative_reflect is True, c and d must be >= 0\n",
    "    if negative_reflect and (c < 0 or d < 0):\n",
    "        msg = \"c and d must be non-negative when negative_reflect is True\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Generate samples from the scaled beta distribution\n",
    "    sample = lower + (upper - lower) * RNG.beta(a=a, b=b, size=size)\n",
    "\n",
    "    # Reflect some values to negative if specified\n",
    "    if negative_reflect:\n",
    "        reflection_mask = RNG.choice([-1, 1], size=size)\n",
    "        return sample * reflection_mask\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22357cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(value: float, size: int | list[int]):\n",
    "    return RNG.choice([-value, value], size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10300830",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_modules = 30\n",
    "adj_dict = create_fully_connected_adjacency(num_of_modules)\n",
    "na_cpg = NaCPG(adj_dict, angle_tracking=True, clipping=False)\n",
    "scaled_beta_n = partial(scaled_beta, size=na_cpg.n)\n",
    "init_state_n = partial(init_state, size=(na_cpg.n, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0faacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 100\n",
    "num_workers = 100\n",
    "optimisers = {\n",
    "    0: ng.optimizers.NgIohTuned,  # meta optimizer\n",
    "    1: ng.optimizers.TwoPointsDE,  # overall\n",
    "    2: ng.optimizers.PortfolioDiscreteOnePlusOne,  # hyperparameter\n",
    "    3: ng.optimizers.CMA,  # control\n",
    "    4: ng.optimizers.TBPSA,  # problems corrupted by noise\n",
    "    5: ng.optimizers.PSO,  # robustness\n",
    "    6: ng.optimizers.ScrHammersleySearchPlusMiddlePoint,  # super parallel\n",
    "    7: ng.optimizers.RandomSearch,\n",
    "}\n",
    "optim = optimisers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0230a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrization = ng.p.Instrumentation(\n",
    "    a=ng.p.Scalar(init=(RNG.uniform(low=0.2, high=4)), lower=0.1, upper=4),\n",
    "    b=ng.p.Scalar(init=(RNG.uniform(low=0.2, high=4)), lower=0.1, upper=4),\n",
    "    c=ng.p.Scalar(\n",
    "        init=(RNG.uniform(low=0, high=1)),\n",
    "        lower=0,\n",
    "        upper=2,\n",
    "    ),\n",
    "    d=ng.p.Scalar(\n",
    "        init=(RNG.uniform(low=0, high=1)),\n",
    "        lower=0,\n",
    "        upper=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "optim_phase = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "optim_amplitudes = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "optim_w = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "optim_ha = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "optim_b = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = -100\n",
    "high = 100\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    coefficients=ng.p.Array(\n",
    "        init=(RNG.uniform(low=low, high=high, size=4)),\n",
    "        lower=low,\n",
    "        upper=high,\n",
    "    ),\n",
    ")\n",
    "\n",
    "optim_cf = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0.000_1\n",
    "high = np.pi\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    value=ng.p.Scalar(init=(RNG.uniform(low=low, high=high))),\n",
    ")\n",
    "\n",
    "optim_xy = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "optim_xy_dot_old = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0.001\n",
    "high = 0.1\n",
    "factor = 10\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    alpha=ng.p.Scalar(\n",
    "        init=(RNG.uniform(low=low, high=high)),\n",
    "        lower=(low / factor),\n",
    "        upper=(high * factor),\n",
    "    ),\n",
    "    dt=ng.p.Scalar(\n",
    "        init=(RNG.uniform(low=low, high=high)),\n",
    "        lower=low,\n",
    "        upper=high,\n",
    "    ),\n",
    ")\n",
    "\n",
    "optim_alpha_dt = optim(\n",
    "    parametrization=parametrization,\n",
    "    budget=budget,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9aeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mean = np.inf\n",
    "best_std = np.inf\n",
    "repeat = 10\n",
    "control_frequency = 0.02\n",
    "total_time = 30  # seconds\n",
    "time_steps = int(total_time / control_frequency)\n",
    "for _ in track(range(budget)):\n",
    "    # Non-learning (overarching parameters)\n",
    "    alpha_dt_asks = optim_alpha_dt.ask()\n",
    "    alpha = alpha_dt_asks.kwargs[\"alpha\"]\n",
    "    dt = alpha_dt_asks.kwargs[\"dt\"]\n",
    "    cf_ask = optim_cf.ask()\n",
    "    coefficients = cf_ask.kwargs[\"coefficients\"]\n",
    "\n",
    "    # Non-learning (state initialization)\n",
    "    state_asks = {\n",
    "        \"xy\": optim_xy.ask(),\n",
    "        \"xy_dot_old\": optim_xy_dot_old.ask(),\n",
    "    }\n",
    "\n",
    "    # Learning\n",
    "    parameter_groups_asks = {\n",
    "        \"phase\": optim_phase.ask(),\n",
    "        \"w\": optim_w.ask(),\n",
    "        \"amplitudes\": optim_amplitudes.ask(),\n",
    "        \"ha\": optim_ha.ask(),\n",
    "        \"b\": optim_b.ask(),\n",
    "    }\n",
    "\n",
    "    # Test loop\n",
    "    losses = []\n",
    "    losses_clip = []\n",
    "    losses_curvature = []\n",
    "    losses_dev = []\n",
    "    for _ in range(repeat):\n",
    "        # Reset CPG\n",
    "        na_cpg.reset_state()\n",
    "\n",
    "        # Set alpha, dt and constraint function coefficients\n",
    "        na_cpg.alpha = alpha\n",
    "        na_cpg.dt = dt\n",
    "        na_cpg.coefficients = coefficients\n",
    "\n",
    "        # Set state\n",
    "        xy = init_state_n(**state_asks[\"xy\"].kwargs)\n",
    "        xy_dot_old = init_state_n(**state_asks[\"xy_dot_old\"].kwargs)\n",
    "        na_cpg.set_state(\n",
    "            xy=xy,\n",
    "            xy_dot_old=xy_dot_old,\n",
    "        )\n",
    "\n",
    "        # Parameter groups\n",
    "        parameter_groups = {\n",
    "            \"phase\": scaled_beta_n(**parameter_groups_asks[\"phase\"].kwargs),\n",
    "            \"w\": scaled_beta_n(**parameter_groups_asks[\"w\"].kwargs),\n",
    "            \"amplitudes\": scaled_beta_n(\n",
    "                **parameter_groups_asks[\"amplitudes\"].kwargs,\n",
    "            ),\n",
    "            \"ha\": scaled_beta_n(**parameter_groups_asks[\"ha\"].kwargs),\n",
    "            \"b\": scaled_beta_n(**parameter_groups_asks[\"b\"].kwargs),\n",
    "        }\n",
    "        # Set the new parameters in the CPG\n",
    "        na_cpg.set_param_with_dict(parameter_groups)\n",
    "\n",
    "        # Run the CPG to evaluate performance\n",
    "        for _ in range(time_steps):\n",
    "            na_cpg.forward()\n",
    "\n",
    "        # Clipping error\n",
    "        loss_clip = na_cpg.clamping_error\n",
    "        losses_clip.append(loss_clip)\n",
    "\n",
    "        # Flat-line error\n",
    "        w = np.arange(len(na_cpg.angle_history))\n",
    "        y = np.mean(na_cpg.angle_history, axis=1)\n",
    "\n",
    "        # Linear fit\n",
    "        m, b = np.polyfit(w, y, 1)\n",
    "\n",
    "        # Deviation from linearity\n",
    "        dev = np.mean(np.abs(m * w - y + b) / np.sqrt(m * m + 1))\n",
    "        losses_dev.append(dev)\n",
    "\n",
    "        # Curvature\n",
    "        curvature = (\n",
    "            np.mean(\n",
    "                (w[2:] - 2 * w[1:-1] + w[:-2]) ** 2\n",
    "                + (y[2:] - 2 * y[1:-1] + y[:-2]) ** 2,\n",
    "            )\n",
    "            if len(w) > 2\n",
    "            else 0\n",
    "        )\n",
    "        # Perfectly straight lines are no good\n",
    "        if round(curvature, 5) == 0:\n",
    "            curvature = 1e6\n",
    "        losses_curvature.append(curvature)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = np.abs(0.0002974789730298905 - curvature)\n",
    "        # total_loss += np.abs(1.221188 - dev)\n",
    "        # total_loss += loss_clip\n",
    "        losses.append(total_loss)\n",
    "\n",
    "    # Compute the final loss\n",
    "    loss_std = np.std(losses)\n",
    "    loss_mean = np.mean(losses)\n",
    "    loss_clip_mean = np.mean(losses_clip)\n",
    "    loss_curvature_mean = np.mean(losses_curvature)\n",
    "    loss_dev_mean = np.mean(losses_dev)\n",
    "\n",
    "    # Tell each optimizer the loss it got\n",
    "    optim_phase.tell(parameter_groups_asks[\"phase\"], loss_mean)\n",
    "    optim_amplitudes.tell(parameter_groups_asks[\"amplitudes\"], loss_mean)\n",
    "    optim_w.tell(parameter_groups_asks[\"w\"], loss_mean)\n",
    "    optim_ha.tell(parameter_groups_asks[\"ha\"], loss_mean)\n",
    "    optim_b.tell(parameter_groups_asks[\"b\"], loss_mean)\n",
    "    optim_xy.tell(state_asks[\"xy\"], loss_mean)\n",
    "    optim_xy_dot_old.tell(state_asks[\"xy_dot_old\"], loss_mean)\n",
    "    optim_alpha_dt.tell(alpha_dt_asks, loss_mean)\n",
    "    optim_cf.tell(cf_ask, loss_mean)\n",
    "\n",
    "    # Log progress\n",
    "    if (loss_mean < best_mean) or (\n",
    "        loss_mean <= (best_mean + (best_mean * 0.05)) and loss_std < best_std\n",
    "    ):\n",
    "        best_mean = loss_mean\n",
    "        best_std = loss_std\n",
    "\n",
    "        console.log(f\"New best loss: {best_mean:.4f}\")\n",
    "        console.log(f\"Clip: {loss_clip_mean:.4f}\")\n",
    "        console.log(f\"Curvature: {loss_curvature_mean:.4f}\")\n",
    "        console.log(f\"Deviation: {loss_dev_mean:.4f}\")\n",
    "\n",
    "        hist = torch.tensor(na_cpg.angle_history)\n",
    "        times = torch.arange(hist.shape[0]) * na_cpg.dt\n",
    "\n",
    "        plt.figure()\n",
    "        for j in range(hist.shape[1]):\n",
    "            plt.plot(times, hist[:, j], label=f\"joint {j}\")\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        plt.ylabel(\"angle\")\n",
    "        plt.title(\"CPG angle histories\")\n",
    "        plt.grid(visible=True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(DATA / \"angle_histories.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-learning (overarching parameters)\n",
    "alpha_dt_asks = optim_alpha_dt.provide_recommendation()\n",
    "alpha = alpha_dt_asks.kwargs[\"alpha\"]\n",
    "dt = alpha_dt_asks.kwargs[\"dt\"]\n",
    "\n",
    "cf_ask = optim_cf.provide_recommendation()\n",
    "coefficients = cf_ask.kwargs[\"coefficients\"]\n",
    "\n",
    "# Non-learning (state initialization)\n",
    "state_asks = {\n",
    "    \"xy\": optim_xy.provide_recommendation(),\n",
    "    \"xy_dot_old\": optim_xy_dot_old.provide_recommendation(),\n",
    "}\n",
    "\n",
    "# Learning\n",
    "parameter_groups_asks = {\n",
    "    \"phase\": optim_phase.provide_recommendation().kwargs,\n",
    "    \"w\": optim_w.provide_recommendation().kwargs,\n",
    "    \"amplitudes\": optim_amplitudes.provide_recommendation().kwargs,\n",
    "    \"ha\": optim_ha.provide_recommendation().kwargs,\n",
    "    \"b\": optim_b.provide_recommendation().kwargs,\n",
    "}\n",
    "\n",
    "# Round decimal places all parameters\n",
    "round_factor = 5\n",
    "alpha = round(alpha, round_factor)\n",
    "dt = round(dt, round_factor)\n",
    "coefficients = np.round(coefficients, round_factor)\n",
    "state_asks = {\n",
    "    \"xy\": {\n",
    "        k: round(v, round_factor) for k, v in state_asks[\"xy\"].kwargs.items()\n",
    "    },\n",
    "    \"xy_dot_old\": {\n",
    "        k: round(v, round_factor)\n",
    "        for k, v in state_asks[\"xy_dot_old\"].kwargs.items()\n",
    "    },\n",
    "}\n",
    "for key in parameter_groups_asks:\n",
    "    for k, v in parameter_groups_asks[key].items():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            parameter_groups_asks[key][k] = np.round(v, round_factor)\n",
    "        else:\n",
    "            parameter_groups_asks[key][k] = round(v, round_factor)\n",
    "\n",
    "console.print(\"Best parameters found:\")\n",
    "console.print(f\"alpha: {alpha:.4f}\")\n",
    "console.print(f\"dt: {dt:.4f}\")\n",
    "console.print(f\"coefficients: {coefficients}\")\n",
    "console.print(f\"xy: {state_asks['xy']}\")\n",
    "console.print(f\"xy_dot_old: {state_asks['xy_dot_old']}\")\n",
    "console.print(f\"phase: {parameter_groups_asks['phase']}\")\n",
    "console.print(f\"w: {parameter_groups_asks['w']}\")\n",
    "console.print(f\"amplitudes: {parameter_groups_asks['amplitudes']}\")\n",
    "console.print(f\"ha: {parameter_groups_asks['ha']}\")\n",
    "console.print(f\"b: {parameter_groups_asks['b']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-learning (overarching parameters)\n",
    "alpha_dt_asks = optim_alpha_dt.ask()\n",
    "alpha = alpha_dt_asks.kwargs[\"alpha\"]\n",
    "dt = alpha_dt_asks.kwargs[\"dt\"]\n",
    "cf_ask = optim_cf.ask()\n",
    "coefficients = cf_ask.kwargs[\"coefficients\"]\n",
    "\n",
    "# Non-learning (state initialization)\n",
    "state_asks = {\n",
    "    \"xy\": optim_xy.ask(),\n",
    "    \"xy_dot_old\": optim_xy_dot_old.ask(),\n",
    "}\n",
    "\n",
    "# Learning\n",
    "parameter_groups_asks = {\n",
    "    \"phase\": optim_phase.ask(),\n",
    "    \"w\": optim_w.ask(),\n",
    "    \"amplitudes\": optim_amplitudes.ask(),\n",
    "    \"ha\": optim_ha.ask(),\n",
    "    \"b\": optim_b.ask(),\n",
    "}\n",
    "\n",
    "# Test loop\n",
    "losses = []\n",
    "losses_clip = []\n",
    "losses_curvature = []\n",
    "losses_dev = []\n",
    "\n",
    "# Reset CPG\n",
    "na_cpg.reset_state()\n",
    "\n",
    "# Set alpha, dt and constraint function coefficients\n",
    "na_cpg.alpha = alpha\n",
    "na_cpg.dt = dt\n",
    "na_cpg.coefficients = coefficients\n",
    "\n",
    "# Set state\n",
    "xy = init_state_n(**state_asks[\"xy\"].kwargs)\n",
    "xy_dot_old = init_state_n(**state_asks[\"xy_dot_old\"].kwargs)\n",
    "na_cpg.set_state(\n",
    "    xy=xy,\n",
    "    xy_dot_old=xy_dot_old,\n",
    ")\n",
    "\n",
    "# Parameter groups\n",
    "parameter_groups = {\n",
    "    \"phase\": scaled_beta_n(**parameter_groups_asks[\"phase\"].kwargs),\n",
    "    \"w\": scaled_beta_n(**parameter_groups_asks[\"w\"].kwargs),\n",
    "    \"amplitudes\": scaled_beta_n(\n",
    "        **parameter_groups_asks[\"amplitudes\"].kwargs,\n",
    "    ),\n",
    "    \"ha\": scaled_beta_n(**parameter_groups_asks[\"ha\"].kwargs),\n",
    "    \"b\": scaled_beta_n(**parameter_groups_asks[\"b\"].kwargs),\n",
    "}\n",
    "# Set the new parameters in the CPG\n",
    "na_cpg.set_param_with_dict(parameter_groups)\n",
    "\n",
    "# Run the CPG to evaluate performance\n",
    "for _ in range(time_steps):\n",
    "    na_cpg.forward()\n",
    "\n",
    "hist = torch.tensor(na_cpg.angle_history)\n",
    "times = torch.arange(hist.shape[0]) * na_cpg.dt\n",
    "\n",
    "plt.figure()\n",
    "for j in range(hist.shape[1]):\n",
    "    plt.plot(times, hist[:, j], label=f\"joint {j}\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"angle\")\n",
    "plt.title(\"CPG angle histories\")\n",
    "plt.grid(visible=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATA / \"angle_histories.png\")\n",
    "plt.show()\n",
    "\n",
    "console.log(na_cpg.clamping_error)\n",
    "console.log(np.mean(np.mean(np.abs(na_cpg.angle_history), axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariel4 (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
